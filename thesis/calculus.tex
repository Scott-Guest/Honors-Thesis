\section{Peanut: A Typed Pattern Hole Calculus}\label{sec:peanut}
We now formalize the high-level discussion described in \autoref{sec:pattern-matching}. While all of our work has been implemented into the full Hazel system, for ease of presentation, we distill our contribution into a bare-bones typed lambda calculus called Peanut. The core of our calculus is based upon the Hazelnut Live internal language \cite{DBLP:journals/pacmpl/OmarVCH19}, but extended to include pattern holes. We develop a dynamic semantics which allows live evaluation as was discussed in \autoref{sec:live-eval}, and additionally, present a static semantics guaranteeing (indeterminate or necessary) exhaustiveness and irredundancy as was discussed in \autoref{sec:exhaustiveness} and \autoref{sec:redundancy}. 

We begin in \autoref{sec:syntax} by presenting the syntax of our calculus. In \autoref{sec:dynamics}, we then provide a small-step dynamic semantics with support for evaluating incomplete programs. In \autoref{sec:constraints}, \autoref{sec:statics}, and \autoref{sec:analyses}, we give the corresponding static semantics as a system of type assignment, making use a constraint language to reason about exhaustiveness and irredundancy. We defer discussion of decidability and implementation until \autoref{sec:decidability}.

\subsection{Syntax}\label{sec:syntax}
\input{fig-syntax}
\input{fig-pointer-erasure}

Figure \ref{fig:syntax} presents the syntax of Peanut. Peanut closely mirrors the internal language of Hazelnut Live \cite{DBLP:journals/pacmpl/OmarVCH19}, a typed lambda calculus with expression holes which provides the base of the Hazel system. To ensure the generality of our approach, we attempt to include only those forms necessary to have a rich discussion of pattern matching. As a result, we remove most of the machinery related to gradual typing \cite{DBLP:conf/snapl/SiekVCB15}, but such an extension is fairly straightforward to implement. Most of the forms are standard, following a formulation outlined in \cite{Harper2012}. 

Unsurprisingly, we include lambda functions and function application. We choose natural numbers as our base type. In order to create interesting expressions to pattern match on, we also allow the formation of binary sum and binary product types. Correspondingly, we include pairs, projection operators, and left and right injections. (Note that pattern matching generally subsumes the need for explicit projections operators, but we include such forms here for reasons discussed later.) To simplify our type assignment system, we also require injections and functions to have explicit type annotations. Such annotations are fairly innocuous, as Peanut represents an internal language, so if desired, annotations can always be inserted during elaboration. Finally, we include the main forms of interest: holes, patterns, and match expressions.

As discussed in \autoref{sec:intro}, holes come in two variants. Empty expression holes are written $\hehole{u}$ and indicate missing syntactic pieces, while non-empty holes expression holes are written $\hhole{e}{u}$, acting as a membrane around a type inconsistency at the expression $e$. Analogously, empty pattern holes are written $\heholep{w}$ and indicate missing sub-terms of a pattern, while non-empty pattern holes are written $\hholep{p}{w}{\tau}$ and surround a type-inconsistency, with $\tau$ recording the type of the wrapped expression $p$. Here, the labels $u$ and $w$ are identifiers for the corresponding holes. As Peanut represents an internal language, distinct hole identifiers should correspond to distinct holes in the original program source code. However, as evaluation can lead to holes being replicated during substitution, we do not enforce a uniqueness constraint on hole identifiers within Peanut itself.

Outside of holes, patterns also include variables, a wildcard $(\_)$, and forms corresponding to each constructor for values. Semantically, the wildcard is matched by any expression, allowing the user to indicate a default case. Match expressions $\hmatch{e}{\zrules}$ then consist of a scrutinee $e$ and a list of rules $\zrules$. As we wish to support live evaluation, we must be able to represent intermediate execution states of the match expression. Correspondingly, the list $\zrules$ follows Huet's zipper construction \cite{DBLP:journals/jfp/Huet97}, effectively containing a pointer to the current rule under consideration. Syntactically, this is given by a triple, $\zruls{rs_{pre}}{r}{rs_{post}}$, with a prefix list of rules already considered, $rs_{pre}$, the current rule, $r$, and a suffix list of rules yet to be considered, $rs_{post}$ . As defined in \autoref{fig:pointer-eraser}, We can erase this pointer through the pointer erasure operator, $\rmpointer{\zrules}$, yielding an unzippered list. Each rule is of the form $\hrul{p}{e}$, where $p$ is a pattern and $e$ is the corresponding branch expression. 

\subsection{Dynamic Semantics}\label{sec:dynamics}

\input{fig-step}
\input{fig-final}

Dynamically, Peanut seeks to extend Hazelnut Live \cite{DBLP:journals/pacmpl/OmarVCH19} while maintaining the ability to evaluate "around" expressions with holes. That is, upon encountering a hole, Peanut should delay its evaluation as long as possible, then proceed to take all other evaluation steps which do not rely on the eventual contents of the hole. For all non-pattern matching forms, our rules correspond exactly to the rules of Hazelnut Live, albeit, formulated as a small-step operational semantics rather than a contextual one. \autoref{fig:step} displays this stepping judgement $\htrans{e}{e'}$, indicating that evaluating an expression $e$ one step yields the expression $e^\prime$.

To begin, consider how one typically evaluates, say, a function application $\hap{e}{e^\prime}$ in a strict language without holes. Initially, the function $e$ is stepped as far as possible, continuing until it is reduced to a value. Next, evaluation steps the argument $e^\prime$, again continuing until it is reduced to a value. Once all these reductions have occurred, only then is the argument actually substituted into the function body. Notably, the key ingredient to this process is the ability to detect when an expression has been reduced "as far as possible", or equivalently, when an expression has been reduced to a value. 

In the presence of pattern and expression holes, evaluation proceeds in much the same way. \autoref{fig:final} defines a judgement $\isFinal{e}$ indicating when an expression $e$ is \emph{final}, i.e when no further evaluation steps can occur. The rules \ITApFun, \ITApArg, and \ITAp are then just as we described in our example. Crucially, however, holes extend the notion of finality to include not just values, but \emph{indeterminate} forms as well. That is, there are terms which have indeed been reduced as far as possible, but they still contain holes in the end result, and they will require further evaluation if such holes are filled at a later point in time. We differentiate between these cases with the judgement $\isVal{e}$, characterizing values, and the judgement $\isIndet{e}$, characterizing indeterminate expressions. Correspondingly, the $\isFinal{e}$ judgement is given as a disjunction of these two cases.

For Peanut, the main task is to describe the behavior of a match expression $\hmatch{e}{\zrules}$. First, as described by \ITExpMatch, we step the scrutinee $e$, eventually yielding either a value or indeterminate form. Once $e$ is final, we then proceed to pattern match, comparing $e$ to each pattern sequentially from the top down. If $e$ indeed matches a pattern, then we step to the corresponding branch expression, applying appropriate substitutions for the bound variables as in the conclusion of \ITSuccMatch. Instead, if $e$ does not match the pattern as in \ITFailMatch, then we move to consider the next rule, using the pointer erasure operator of \autoref{fig:pointer-eraser} to increment the zipper. Note that, per our previous discussion, an expression may also indeterminately match a pattern. The \IMatch rule in the $\isIndet{e}$ judgement covers this case, indicating that we cannot safely proceed past an indeterminate pattern match, leading to the entire match expression being indeterminate without further hole-filling.

Our stepping and finality judgements indeed cover all possible cases. The following theorem states this, combining progress and determinism. Here, the judgement $\hexptyp{\cdot}{\Delta}{e}{\tau}$ indicates that $e$ is a closed term of type $\tau$, as discussed further in \autoref{sec:statics} when presenting Peanut's static semantics.

\begin{theorem}[Deterministic Progress]
	\label{theorem:determinism}
	If $\hexptyp{\cdot}{\Delta}{e}{\tau}$ then exactly one of the following holds
	\begin{enumerate}
		\item $\isVal{e}$
		\item $\isIndet{e}$
		\item $\htrans{e}{e'}$ for some unique $e'$
	\end{enumerate}
\end{theorem}

Essential to the aforementioned rules are the judgements determining whether an expression $e$ must match, must not match, or indeterminately matches a pattern $p$. \autoref{fig:patmatch} presents these three cases. First, the judgement $\hpatmatch{e}{p}{\theta}$ indicates that $e$ successfully matches $p$, emitting a series of corresponding substitutions $\theta$ for the variables bound in $p$. Next, the judgement $\hnotmatch{e}{p}$ indicates that $e$ does not match $p$. Finally, the judgement $\hmaymatch{e}{p}$ indicates that $e$ indeterminately matches $p$ depending on the eventual contents of holes in $e$ or $p$. These judgements correspond respectively to the rules \ITSuccMatch, \ITFailMatch, and \IMatch discussed above, appearing as a premise in each.

\pagebreak

\input{fig-patmatch}

Lemma~\ref{lemma:match-determinism} states that, as desired, these three matching judgements are exclusive and cover all possible cases. Here, the judgement again $\hexptyp{\cdot}{\Delta}{e}{\tau}$ specifies that $e$ is a closed term of type $\tau$, while the judgement $\hpattyp{p}{\tau}{\Gamma}{\Delta}$ indicates that we can also assign the type $\tau$ to our pattern $p$. Note that because of the aforementioned correspondence between these matching judgements and the semantics of the match expression, Lemma~\ref{lemma:match-determinism} encapsulates the majority of the work required to prove \autoref{theorem:determinism}.

\begin{lemma}[Matching Determinism]
	\label{lemma:match-determinism}
	If $\isFinal{e}$ and $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\hpattyp{p}{\tau}{\Gamma}{\Delta}$ then exactly one of the following holds
	\begin{enumerate}
		\item $\hpatmatch{e}{p}{\theta}$ for some $\theta$
		\item $\hmaymatch{e}{p}$
		\item $\hnotmatch{e}{p}$
	\end{enumerate}
\end{lemma}

Let us now explore these pattern matching judgements in more depth. Note that semantics of our expression guarantees that we only perform pattern matching on well-typed and final scrutinees (per the inclusion of $\isFinal{e}$ as a premise to \ITSuccMatch and \ITFailMatch). Throughout this discussion, we then consider matching an expression $e$ against a pattern $p$, assuming $e$ is final and that $e$ and $p$ are of the same type.

If we ignore cases of indeterminacy, most of the rules are fairly straightforward. For the judgement $\hpatmatch{e}{p}{\theta}$, each rule specifies that $e$ and $p$ have the same outermost constructor, and that their corresponding subterms match inductively. Conversely, the rules for $\hnotmatch{e}{p}$ identify cases where either the outermost constructors of $e$ and $p$ mismatch (e.g. \NMConfL and \NMConfR), or where their outermost constructors agree, but some corresponding subterm inductively fails to match (e.g. \NMPairL and \NMPairR). To reason about indeterminacy, however, we require a few auxillary judgements which are defined in \autoref{fig:notintro} and \autoref{fig:refutable}.\\

\input{fig-notintro}
\input{fig-refutable}

\pagebreak

As we consider only final scrutinees, in the context of our matching judgements, an expression $e$ is indeterminate if and only if it is not a value. \autoref{fig:notintro} defines a judgement $\notIntro{e}$ which characterizes this case, syntactically analyzing the outermost constructor of $e$ to determine that it cannot be a value. Note that an indeterminate $e$ will be further evaluated after hole filling, so correspondingly, our rules should treat such an $e$ as opaque, never inspecting any of its subterms for matching purposes. However, even with this restriction, there are still cases where an indeterminate $e$ must match a pattern $p$. In particular, a pattern $p$ could be irrefutable in the sense that it must be matched by all expressions of the same type, say, if it is a variable \li{x} or wildcard $\_$. Correspondingly, \autoref{fig:refutable} defines a judgement $\refutable{p}$ indicating that $p$ is not necessarily irrefutable, i.e. there is some hole filling which allows at least one expression to fail to match $p$.

Together, the combination of these judgements allows us to handle matching with indeterminacy. The rule \MMNotIntro gives that a match is indeterminate whenever $e$ is indeterminate, so long as $p$ is not necessarily irrefutable. The rules \MMEHole and \MMHole state that directly matching against a hole will always be indeterminate. All other indeterminate matches arise inductively from some subterms indeterminately matching. Conversely, even in the case when $e$ is indeterminate, we wish to have $e$ match an irrefutable pattern $p$. The rules \MVar and \MWild give two explicit cases of this. In \MNotIntroPair, the irrefutability premise is implicit - a term $\hfst{e}$ or $\hsnd{e}$ can only match an irrefutable pattern, but we explicitly derive the matching judgements in order to emit appropriate substitutions. This also motivates the inclusion of explicit projection operators, despite the fact that pattern matching also allows deconstructing of pairs.

\subsection{Match Constraint Language}\label{sec:constraints}
With the dynamic semantics of Peanut defined, we now turn to the problem of statically reasoning about the runtime behavior of our programs. We extend an idea outlined in \cite{Harper2012} by introducing a \emph{match constraint language}. Intuitively, constraints encode the logic of patterns, with each constraint corresponding to the restriction that a pattern puts on those expression matching it. Further, we allow taking boolean combinations of constraints using negation, logical and ($\land$), and logical or ($\lor$). In \autoref{sec:statics}, we describe how constraints are generated by patterns. In \autoref{sec:analyses}, we then describe how constraints enable static reasoning about exhaustiveness and irredundancy.

\input{fig-constraint}

The syntax of the constraint language is displayed in \autoref{fig:constraint}. Note that each pattern indeed has a corresponding constraint of the same syntactic form. The only exception here is that variables and wildcards both map to constraint ($\ctruth$), as they are both matched by any expression, and both forms of pattern holes map to an unknown constraint ($\cunknown$). We specify that a constraint $\xi$ restricts expressions of type $\tau$ using the constraint type assignment judgement $\ctyp{\xi}{\tau}$. 

Ignoring indeterminacy and $\cunknown$ for now, one can explicitly model constraints of type $\tau$ as the Boolean algebra of sets of final expressions of type $\tau$ under intersection, union, and complement. That is, a constraint $\ctyp{\xi}{\tau}$ can be interpreted as the set of all final expressions $e$ of type $\tau$ such that $e$ \emph{satisfies} the restriction represented by $\xi$. The truth constraint $\ctruth$ and falsity constraint $\cfalsity$ are then interpreted as the whole set and the empty set respectively. Likewise, \autoref{fig:constraint} defines a negation operator called the \emph{dual} of a constraint. Written $\cdual{\xi}$, the dual of $\xi$ is satisfied by all appropriately-typed final expressions not satisfying $\xi$. In our model, $\cdual{\xi}$ identifies the complement of the set identified by $\xi$. Up to equivalence, the usual laws of Boolean logic hold, e.g. the dual of $\cdual{\xi}$ is equivalent to $\xi$.

\input{fig-satisfy}

Just as we introduced pattern holes into patterns, we include an unknown constraint $(\cunknown)$ in our constraint language to represent indeterminacy. Correspondingly, we have analogs of the three pattern matching judgements - for a final expression $e$ and constraint $\xi$ of the same type as $e$, either $e$ \emph{must satisfiy} $\xi$, $e$ \emph{must not satisfy} $\xi$, or $e$ \emph{indeterminately satisfies} $\xi$ due to the presence of holes or the unknown constraint. \autoref{fig:satisfy} explicitly defines these judgements. The judgement $\csatisfy{e}{\xi}$ specifies that $e$ satisfies $\xi$, the judgement $\cmaysatisfy{e}{\xi}$ specifies that $e$ may satisfy $\xi$, and the judgement $\csatisfyormay{e}{\xi}$ provides the disjunction of these two cases. Note that we do not include a corresponding "$e$ does not satisfy $\xi$" judgement, but rather reason about the non-derivability of $\csatisfyormay{e}{\xi}$.

The rules for each of these satistfaction judgements almost exactly mirror the corresponding rules for the pattern matching judgements. The only notable difference is between the rules \MMNotIntro and \CMSNotIntro. Recall that \MMNotIntro captures the notion that an indeterminate expression $e$ should indeterminately match any pattern $p$, excluding the edge case where $p$ is matched by all expressions in all hole-fillings. While \CMSNotIntro captures this same notion, it additionally must consider the edge case where a constraint $\xi$ is impossible to match at all. With patterns, this is not a concern, as every pattern is matchable by at least one expression. To accomplish this, the $\possible{\xi}$ judgement defined in \autoref{fig:xi-possible} specifies that $\xi$ is possibly satisfied by at least one expression, i.e. it is not equivalent to $\cfalsity$. We also define a $\refutable{\xi}$ judgement in \autoref{fig:xi-refutable}, which exactly corresponds to the $\refutable{p}$ judgement for patterns. 

\input{fig-xi-possible}
\input{fig-xi-refutable}

Expectedly, one can prove that there is indeed a correspondence between a pattern and its emitted constraint. The judgement $\chpattyp{p}{\tau}{\xi}{\Gamma}{\Delta}$ indicates that a pattern $p$ emits the constraint $\xi$, but we defer a more in depth discussion until \autoref{sec:statics}.

\begin{lemma}[Matching Coherence of Constraint]
	\label{lemma:const-matching-coherence}
	Suppose that $\hexptyp{\cdot}{\Delta_e}{e}{\tau}$ and $\isFinal{e}$ and $\chpattyp{p}{\tau}{\xi}{\Gamma}{\Delta}$. Then we have
	\begin{enumerate}
		\item $\csatisfy{e}{\xi}$ iff $\hpatmatch{e}{p}{\theta}$
		\item $\cmaysatisfy{e}{\xi}$ iff $\hmaymatch{e}{p}$
		\item $\cnotsatisfyormay{e}{\xi}$ iff $\hnotmatch{e}{p}$
	\end{enumerate}
\end{lemma}

\pagebreak
 
Combining Lemma~\ref{lemma:const-matching-coherence} with Lemma~\ref{lemma:match-determinism}, we may also verify that the various constraint satisfaction judgements are mutually exclusive and cover all possibilities.

\begin{theorem}[Exclusiveness of Constraint Satisfaction]
	\label{theorem:exclusive-constraint-satisfaction}
	If $\ctyp{\xi}{\tau}$ and $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isFinal{e}$ then exactly one of the following holds
	\begin{enumerate}
		\item $\csatisfy{e}{\xi}$
		\item $\cmaysatisfy{e}{\xi}$
		\item $\cnotsatisfyormay{e}{\xi}$
	\end{enumerate}
\end{theorem}

With the setup of our constraint language clear, let us return to the issue of redundancy and exhaustiveness checking. For now, we focus only on defining these notions in terms of constraints, deferring discussion of their actual implementation until \autoref{sec:decidability}.

Consider if we have a zippered list of rules $\zruls{rs_{pre}}{r}{rs_{post}}$ with the currently considered rule $r$ given by $\hrul{p}{er}$. Recalling the discussion in \autoref{sec:redundancy}, we state that $r$ is redundant if it is unreachable in any hole filling, i.e. if any expression which could possibly reach $r$ will instead match against one of the rules in $rs_{pre}$. Stated formally, $r$ will be redundant if for all appropriately-typed final expressions $e$, if either $\hpatmatch{e}{p}{\theta}$ or $\hmaymatch{e}{p}$ is derivable then so is $\hpatmatch{e}{p^\prime}{\theta^\prime}$ for some pattern $p^\prime$ in a previous rule. Using \autoref{lemma:const-matching-coherence}, we can translate this into a statement about constraints. That is, a constraint $\xi$ is redundant if any appropriately-typed expression $e$ with $\csatisfyormay{e}{\xi}$ necessarily has $\csatisfy{e}{\xi_{pre}}$ for some constraint $\xi_{pre}$ emitted by a pattern earlier in the sequence. In fact, as we may take the logical or of constraints, we can consider just a single $\xi_{pre}$ taken as the disjunction of all previously emitted constraints. This inspires the following definition of \emph{entailment}.

\begin{definition}[Indeterminate Entailment of Constraints]
	\label{definition:const-entailment}
	Suppose that $\ctyp{\xi_1}{\tau}$ and $\ctyp{\xi_2}{\tau}$.
	Then $\csatisfy{\xi_1}{\xi_2}$ iff for all $e$ such that $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isVal{e}$ we have $\csatisfyormay{e}{\xi_1}$ implies $\csatisfy{e}{\xi_2}$
\end{definition}
Correspondingly, if $\xi_{pre}$ is the disjunction of all constraints emitted by the previously considered rules in a match, and if $\xi$ is the constraint emitted by the current rule, then the current rule is necessarily redundant if and only if $\csatisfy{\xi}{\xi_{pre}}$. Conversely, to ensure a rule is either necessarily or indeterminately irredundant, we must check that $\cnotsatisfy{\xi}{\xi_{pre}}$. In our yet-to-be-discussed static system, such checks are added as a premise in the typing rules \TOneRules and \TRules.

It is worth emphasizing that the above definition identifies \emph{necessary} redundancy rather than \emph{indeterminate} redundancy. Indeed, indeterminate redundancy may be resolved by further hole-filling, so we do not yet desire to report an error to the user. Likewise with exhaustiveness checking, we only wish to report an error in cases of \emph{necessary} inexhaustiveness. To that end, conversely, we must be able to identify when a constraint is either \emph{necessarily} exhaustive or \emph{indeterminately} exhaustive. This is captured by a slightly weaker notion of entailment.

\begin{definition}[Potential Entailment of Constraints]
	\label{definition:nn-entailment}
	Suppose that $\ctyp{\xi_1}{\tau}$ and $\ctyp{\xi_2}{\tau}$. Then $\csatisfyormay{\xi_1}{\xi_2}$ iff for all $e$ such that $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isFinal{e}$ we have $\csatisfyormay{e}{\xi_1}$ implies $\csatisfyormay{e}{\xi_2}$ 
\end{definition}
We can then state that a constraint $\xi$ is either necessarily or indeterminately exhaustive exactly when $\csatisfyormay{\ctruth}{\xi}$, relying on the fact that every expression possibly satisfies the truth constraint $\ctruth$. That is, $\xi$ is not necessarily inexhaustive if every expression possibly satisfies $\xi$. 

\input{fig-values}

Note that the definition of potential entailment quantifies over all final expressions rather than just those $e$ with $\isVal{e}$. Resultingly, so long as the constraint $\xi$ emitted by a list of rules has $\csatisfyormay{\ctruth}{\xi}$, any scrutinee, either a value or indeterminate form, will possibly match at least one of the patterns in the rule, preventing evaluation from getting stuck. Such a definition simplifies the proof of progress in \autoref{theorem:determinism}. However, as the following lemma states, exhaustiveness over values also ends up being sufficient.

\begin{lemma}
	\label{lem:val-final-satormay}
	Suppose $\ctyp{\hxi}{\tau}$. Then $\csatisfyormay{e}{\hxi}$ for all $e$ such that $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isFinal{e}$ if and only if $\csatisfyormay{e}{\hxi}$ for all $e$ such that $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isVal{e}$.
\end{lemma}

To prove this, we reason about the possible values that result when filling holes in an indeterminate expression. Formally, the judgement $\inValues{e'}{\Delta}{e}$ defined in \autoref{fig:values} indicates that $e'$ is one of the possible values of $e$ after hole-filling. Here, $\Delta$ is a hole context used for typing information, which we discuss further in \autoref{sec:statics}. Using such a judgment, Lemma~\ref{lem:val-final-satormay} follows straightforwardly from the ensuing lemma.

\begin{lemma}
	\label{lem:complete-not-satormay}
	Assume $\isFinal{e}$ and $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and
	$\ctyp{\hxi}{\tau}$. If $\cnotsatisfyormay{e}{\hxi}$, then for any $e^\prime$ with
	$\inValues{e'}{\Delta}{e}$ we also have $\cnotsatisfyormay{e'}{\hxi}$.
\end{lemma}

\subsection{Static Semantics}\label{sec:statics}
 We are now ready to present the static semantics of Peanut, using the discussed match constraint language to enforce exhaustiveness and irredundancy of well-typed terms. Again, our type system is based on the internal language of Hazelnut Live \cite{DBLP:journals/pacmpl/OmarVCH19}, but extended to include typing of both patterns and expressions. Throughout, we use expression contexts $\Gamma$ to map variable names to types, and we use hole contexts $\Delta$ to map both expression and pattern hole names to their corresponding types.
 
 \input{fig-pat-rulestyp}
  
 \pagebreak
 
 \subsubsection{Typing of Rules and Emitted Constraints}
 We begin by formalizing pattern typing and the relationship between patterns and constraints. \autoref{fig:pat-rulestyp} presents three judgements specifying typing for patterns $p$, a single rule $r$, and a series of rules $rs$. All of the judgements here record the emitted constraints, and additionally, are used to enforce irredundancy.
 
 For patterns, the judgement $\chpattyp{p}{\tau}{\xi}{\Gamma}{\Delta}$ specifies that, in the hole context $\Delta$, the pattern $p$ is assigned the type $\tau$, emits the constraint $\xi$, and makes typing assumptions about bound variables as recorded in the expression context $\Gamma$. Note that, unlike in any other of our typing judgements, the expression context $\Gamma$ is morally an output for pattern typing rather than an input. Rules \PTVar and \PTWild specify that wildcards and variables may be assigned any time, and as they may be matched by any expression, they emit only a truth constraint $\ctruth$. Rules \PTEHole and \PTHole specify that pattern holes emit the unknown constraint $?$, inductively checking that the content of a non-empty hole are also well-typed. All of these rules should be unsurprising.
 
 Once we have specified pattern typing, we can then check the type of a rule. Intuitively, a rule $\hrul{p}{e}$ if both $p$ and $e$ are well-typed, with $e$ possibly referencing the variables bound in $p$. Correspondingly, when we specify the type of $e$, we use the context $\Gamma \uplus \Gamma_p$, where $\Gamma_p$ records assumptions about the types of bound variables in $p$ as emitted by the judgement $\chpattyp{p}{\tau}{\xi}{\Gamma_p}{\Delta}$. Note that we need never extend the context $\Delta$, as we assume it to already include all expression and hole types in the original program source code. In summary then, the rule typing judgement $\chrultyp{\Gamma}{\Delta}{\hrulP{p}{e}}{\tau}{\xi}{\tau'}$ specifies that $r$ matches expressions of type $\tau$ and evaluates to a corresponding branch expression of type $\tau^\prime$, emitting constraint $\xi$.
 
 Finally, for later use in type checking match expression, we define typing for an entire sequence of rules $rs$. With the full rule sequence now available, we also are able to enforce irredundancy. Intuitively, the judgement $\chrulstyp{\Gamma}{\Delta}{\xi_{pre}}{rs}{\tau}{\xi_{rs}}{\tau'}$ states that all of the rules in $rs$ are matched by expressions of the same type $\tau$, and they all have corresponding branch expressions of the same type $\tau^\prime$. Moreover, it states that the disjunction of the all rules together emits the constraint $\xi_{rs}$, and crucially, that this emitted constraint does not entail another constraint $\xi_{pre}$. Morally, $\xi_{pre}$ is an input to the judgement which records the constraint emitted by all previously considered rules. Thus, checking that $\cnotsatisfy{\xi_{rs}}{\xi_{pre}}$ ensures irredundancy.
 
To accomplish this, the rule \TOneRules delegates to the single rule typing judgement, while also adding a premise $\cnotsatisfy{\xi_{r}}{\xi_{pre}}$ to ensure irredundancy. For the inductive case of a list $\hrules{r}{rs}$, we consider the rules one-by-one, analogously to how a match expression considers rules one-by-one from the top down. Correspondingly, the first premise of \TRules specifies that the head of the list $r$ is well-typed and irredundant with respect to $\xi_{pre}$. In turn, the second premise takes the constraint $\xi_r$ emitted by $r$, appends it the constraint $\xi_{pre}$ emitted by all previously considered rules, then inductively uses this as input when checking the tail of the list $rs$. At the same time, we record the constraint emitted by $\hrules{r}{rs}$ as $\cor{\xi_r}{\xi_{rs}}$, the disjunction of the constraint emitted by $r$ and that emitted by $rs$.

\input{fig-exptyp}

\subsubsection{Typing of Expressions}
 We are now able to present the full typing judgement for expressions. For all non-pattern matching forms, the rules are standard, with our inclusion of type annotations on functions and injections enabling a simple system of type assignment. \autoref{fig:exptyp} displays the definitions for the judgement $\hexptyp{\Gamma}{\Delta}{e}{\tau}$ indicating that an expression $e$ has type $\tau$, where the types of free variables are recorded in a context $\Gamma$, and the types of expression and pattern holes from the original source code are recorded in a context $\Delta$ (recall that Peanut is an internal language). The only rules of interest to us are those for the match expression, \TMatchZPre and \TMatchNZPre.
 
Considering the zippered rule list, \TMatchZPre represent the case where have not yet started pattern matching, and there are no previously considered rules. The first premise checks that the scrutinee is well-typed. The second premise ensures that the rules are all matchable by expressions of the same type $\tau$, and that all have branch expressions of type $\tau^\prime$. Correspondingly, as a the match expression will ultimately evaluate to one of these branch expressions, the type of the entire match is also $\tau^\prime$. Note that, because there are no previously considered rules, the second premise need only check irredundancy with respect to the constraint $\cfalsity$, which should never be entailed by any constraint $\xi$ with $\possible{\xi}$ (and in particular, any constraint emitted by a pattern).

For \TMatchNZPre, we are now considering the case where we are in the midst of pattern matching, having already considered the rules $rs_{pre}$ and currently considering the rule $r$. As pattern matching should only proceed once a scrutinee is fully evaluated, we add a premise requiring $\isFinal{e}$. Additionally, to ensure that it was valid to reach this point in the rule list, the scrutinee should not have matched any previously considered rules, hence we add a premise $\cnotsatisfyormay{e}{\xi_{pre}}$. Indeed, \autoref{lemma:const-matching-coherence} ensures this is the case. As well, we again require that the rules are well-typed, checking this piecewise - first with the previously considered rules $rs_{pre}$, then with the remaining rules $\hrules{r}{rs_{post}}$. Finally, we ensure exhaustiveness on the total emitted constraint as $\csatisfyormay{\ctruth}{\cor{\xi_{pre}}{\xi_{rest}}}$.

Thus, our system indeed ensures a term is well-typed only if it also both exhaustive and irredundant, either necessarily or indeterminately. Alternatively, one could also extract these checks as their own judgements separate from the type system, although exhaustiveness is still required to ensure progress in \autoref{theorem:determinism}. We take this alternative in the Agda mechanization of \autoref{sec:mechanization}.

\subsubsection{Type Safety}
The type safety of Peanut is established by \autoref{theorem:determinism} and \autoref{theorem:preservation}.

\begin{theorem}[Preservation]
	\label{theorem:preservation}
	If $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\htrans{e}{e'}$
	then $\hexptyp{\cdot}{\Delta}{e'}{\tau}$
\end{theorem}
While we do not enumerate them here, the proof of preservation relies on a number of small lemmas showing that our various typing and finality judgements are well-behaved with respect to substitution (in particular, when applying a substitution list $\theta$ emitted by the judgement $\hpatmatch{e}{p}{\theta}$). The details can be found in our mechanization.

\subsection{Eliminating Indeterminacy}\label{sec:analyses}
Thus far, we have managed to describe a type system encoding exhaustiveness and irredundancy checking using constraint entailment. However, it is quite unclear how to actually check when such entailment holds - our definitions require quantifying over all final expressions of a given type, yielding no obvious decision procedure. To make matters worse, our definitions also involve indeterminate satisfaction, requiring us to reason conservatively about all possible hole-fillings through the unknown constraint $(\cunknown)$. In this section, as a first step towards resolving these complications, we discuss how to remove all such indeterminacy, eliminating any use of $\cunknown$ from the constraints involved in an entailment. We forgo discussion of the full decision procedure until \autoref{sec:decidability}.

Recall that, for exhaustiveness, we only report an error when a  match expression is \emph{necessarily inexhaustive}, or equivalently, when it is inexhaustive regardless of how the programmer chooses to fill any pattern holes. In particular, such a match expression should still be inexhaustive even in the most permissive of hole-fillings, i.e. when all pattern holes are treated as wildcards. Conversely, if a match expression is inexhaustive with this most permissive hole-filling, then it will also certainly be inexhaustive given any more restrictive hole-filling. As a result of this, we can state that a match expression is necessarily inexhaustive if and only if it is inexhaustive when all pattern holes are filled with wildcards. 

As discussed, we use constraints to encode exhaustiveness. Considering the definitions in \autoref{fig:pat-rulestyp}, a pattern hole emits an unknown constraint $?$, while a wildcard emits the truth constraint $\ctruth$. Correspondingly, filling pattern holes with wildcards replaces all instances of $\cunknown$ with $\ctruth$ in the emitted constraint. To that end, \autoref{fig:truify-falsify} defines a function $\ctruify{\xi}$ performing such an operation. We refer to this as \emph{truifying} the constraint. 

\input{fig-truify-falsify}

With all indeterminacy eliminated, we can now define a simpler notion of exhaustiveness known as \emph{constraint validity}. Here, the premise $\ctruify{\xi} = \xi$ specifies that $\xi$ no longer contains any instances of the unknown constraint. We call such a $\xi$ a \emph{fully known} constraint.

 \begin{definition}[Validity of Constraints]
 	\label{definition:valid-constraint}
 	Suppose that $\ctruify{\xi}=\xi$ and $\ctyp{\xi}{\tau}$.
 	Then $\ccsatisfy{}{\xi}$ if and only if for all $e$ such that $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isVal{e}$ we have $\ccsatisfy{e}{\xi}$
 \end{definition}

The following theorem formalizes the above discussion, stating that a constraint is exhaustive if and only if truifying it produces a valid constraint. A proof is provided in our Agda mechanization.

\begin{theorem}
	\label{theorem:exhaustive-truify}
	$\csatisfyormay{\ctruth}{\xi}$ if and only if $\ccsatisfy{\;}{\ctruify{\xi}}$.
\end{theorem}

We now make a similar argument regarding redundancy. Recall that a rule $r$ is necessarily redundant with respect to the previously considered rules $rs$ if, considering any possible hole filling, those expressions $e$ which match the pattern in $r$ also necessarily match some pattern in $rs$. In the worst case then, any expression $e$ which matches the most permissive hole filling of $r$ should still match some pattern in $rs$, even if we attempt to adversarially fill the pattern holes in $rs$ as to prevent any subterm of $e$ from matching them. That is, we should consider the most permissive hole filling of $r$ but the most restrictive hole filling of $rs$. In terms of constraints, if $r$ emits $\xi_r$ and $rs$ emits $\xi_{rs}$, then $r$ is necessarily redundant with repsect to $rs$ when $\csatisfy{\xi_r}{\xi_{rs}}$. To that end, \autoref{fig:truify-falsify} also defines a \emph{falsify} function $\cfalsify{\xi}$ which replaces every instance of $\cunknown$ in $\xi$ with $\bot$, corresponding to the most restrictive hole filling. The following theorem formalizes our discussion.

\begin{theorem}
	\label{theorem:redundant-truify-falsify}
	$\csatisfy{\xi_1}{\xi_2}$ if and only if $\ccsatisfy{\ctruify{\xi_1}}{\cfalsify{\xi_2}}$.
\end{theorem}

Further, considering dual as negation and entailment as implication, one can prove something akin to the material implication of propositional logic, transforming constraint entailment into constraint validity. In effect, this demonstrates a "fully known" equivalence between redundancy and exhaustiveness.

\begin{lemma}[Material Entailment]
	\label{lemma:material-entailment}
	Suppose $\xi_1$ and $\xi_2$ are fully known constraints. Then $\csatisfy{\xi_1}{\xi_2}$ if and only if $\ccsatisfy{\;}{\cor{\cdual{\xi_1}}{\xi_2}}$.
\end{lemma}

Combined with \autoref{theorem:redundant-truify-falsify}, we can then state necessary redundancy in terms of validity.

\begin{theorem}
	\label{theorem:redundant-validity}
	$\csatisfy{\xi_r}{\xi_{rs}}$ if and only if $\ccsatisfy{\;}{\cor{\cdual{\ctruify{\xi_r}}}{\cfalsify{\xi_{rs}}}}$.
\end{theorem}

\subsection{Implementation and Decidability}\label{sec:decidability}
Considering \autoref{theorem:exhaustive-truify} and \autoref{theorem:redundant-validity}, we have now reduced both exhaustiveness and irredundancy checking to the problem of constraint validity. Thus, to provide actual implementations of these checks, all that remains to provide an algorithm deciding whether a given constraint $\xi$ is valid. The ensuing theorem provides the key ingredient needed to implement such a procedure.

\begin{theorem}[Exclusiveness of Satisfaction Judgment]
	\label{theorem:exclusive-complete-constraint-satisfaction}
	If $\ctyp{\xi}{\tau}$ and $\hexptyp{\cdot}{\Delta}{e}{\tau}$ and $\isVal{e}$ then exactly one of the following holds
	\begin{enumerate}
		\item $\ccsatisfy{e}{\xi}$
		\item $\ccsatisfy{e}{\cdual{\xi}}$
	\end{enumerate}
\end{theorem}

We say that a fully known constraint $\ctyp{\xi}{\tau}$ is $\emph{inconsistent}$ if no value of type $\tau$ satisfies $\xi$. From the above theorem, it immediately follows that a fully known constraint $\xi$ is valid if and only if its dual $\bar{\xi}$ is inconsistent. Thus, to decide validity, it suffices to provide a decision procedure for inconsistency, and fortunately, inconsistency is syntactically quite obvious.

\input{fig-incon}

To this end, \autoref{fig:incon} defines a judgement  $\cincon{\Xi}$ specifying that the conjunction over a set of constraints $\Xi$ is inconsistent. Here, we choose to use a set of constraints rather than a single constraint, as conceptually, a single constraint may really represent a boolean combination of many smaller constraints, and our rules require reasoning simultaneously about all these constituent parts. By abuse of notation, for a single constraint $\xi$, we write $\cincon{\xi}$ to denote $\cincon{\{\xi\}}$ for the singleton set $\{\xi\}$.

\autoref{theorem:validity-inconsistency} states that our judgement behaves as desired. Note that, unlike all other work we have presented thus far, we do not provide an Agda mechanization for results involving the $\cincon{\Xi}$ judgement.  While intuitively straightforward, the algorithms and proofs here require manipulations of finite sets which are not obviously structurally recursive, making them inordinately cumbersome to implement in Agda.

\begin{theorem}
\label{theorem:validity-inconsistency}
If $\xi$ is fully known, then $\csatisfy{\;}{\xi}$ if and only if\; $\cincon{\cdual{\xi}}$.
\end{theorem}

Let us discuss the $\cincon{\Xi}$ judgement in more detail. Throughout, we assume all constraints present in $\Xi$ are of the same type. To begin, logical connectives are handled in a straightforward way. Rule \CINCAnd specifies that a set including the constraint $\cand{\xi_1}{\xi_2}$ is inconsistent exactly when it is inconsistent including both $\xi_1$ and $\xi_2$ together. Likewise, rule \CINCOr specifies that a set including $\cor{\xi_1}{\xi_2}$ is inconsistent only if it is inconsistent both when including only $\xi_1$ and when including only $\xi_2$. As we will soon discuss, algorithmically, these judgements allow us to "flatten" any constraints in our inconsistency decision procedure, removing all instances of $\land$ and $\lor$.

Outside of logical connectives, we need only consider how inconsistency can arise for each type. For example, a set of constraints on numbers contains only constraints of the form $\cnum{n}$ and $\cnotnum{n}$. If $\cnum{n}$ and $\cnotnum{n}$ are both included for a single $n$, this is clearly inconsistent, and likewise if $\cnum{n_1}$ and $\cnum{n_2}$ are both included when $n_1 \neq n_2$. \CINCNum and \CINCNotNum handles these cases. For binary sums, inconsistency only occurs if either different constructors are specified as in \CINCInj, or if the same constructors are specified, but the constraints contained within said constructors are inductively inconsistent as in \CINCInl and \CINCInr. Binary products proceed similarly, inductively considering inconsistency on each coordinate as in \CINCPairL and \CINCPairR.

Considering each of the rules for $\cincon{\Xi}$, all premises only involve constraints that are proper components of the constraints in the corresponding conclusion. Consequently, $\cincon{\Xi}$ is decidable by simply inverting each applicable rule until there are no such rules remaining. Eventually, we will either hit a case requiring no induction in its premise - one of \CINCFalsity, \CINCNum, \CINCNotNum, and \CINCInj~ - implying inconsistency. Otherwise, we reach the point where no rules are applicable, implying consistency. 

A full decision procedure $incon(\Xi)$ is shown below. Following our actual OCaml implementation, we choose to represent $\Xi$ as an ordered list of constraints, and thus proceed from the head onward.

\begin{enumerate}
\item If $\Xi$ is empty, return \li{false}. Otherwise, let $\Xi = \xi, \Xi^\prime$.
\item If $\xi = \cfalsity$, return \li{true}.
\item If $\xi = \ctruth$, return $incon(\Xi^\prime)$.
\item If $\xi = \cand{\xi_1}{\xi_2}$, return $incon(\xi_1, \xi_2, \Xi^\prime)$.
\item If $\xi = \cor{\xi_1}{\xi_2}$, return $incon(\xi_1, \Xi^\prime) \land incon(\xi_2, \Xi^\prime)$.
\item Partition $\Xi$, letting $\Xi_{log}$ contain all constraints of the form $\cor{\xi_1}{\xi_2}$ or $\cand{\xi_1}{\xi_2}$ and letting $\Xi_{other}$ contains all other constraints. If $\Xi_{log}$ is non-empty, return $incon(\Xi_{log} \texttt{++}~ \Xi_{other})$.
\item If $\xi = \cinl{\xi^\prime}$ or $\xi = \cinr{\xi^\prime}$, return \li{true} if $\Xi^\prime$ contains any mismatching injection constructor. Otherwise, strip the outermost injection constructor from each element of $\Xi^\prime$ to produce a list $\Xi^\prime_{str}$, then return $incon(\xi^\prime, \Xi^\prime_{str})$.
\item If $\xi = \cpair{\xi_1, \xi_2}$, let $\Xi^\prime_1$ be the result of mapping $\cpair{\xi_1}{\xi_2} \mapsto \xi_1$ onto $\Xi^\prime$, and similarly, let $\Xi^\prime_2$ be the result of mapping $\cpair{\xi_1}{\xi_2} \mapsto \xi_2$ onto $\Xi^\prime$. Return $incon(\xi_1, \Xi^\prime_1) \lor incon(\xi_2, \Xi^\prime_2)$.
\item If $\xi = \cnum{n}$ or $\xi = \cnotnum{n}$, then partition $\Xi$ into two lists, letting $\Xi_{yes}$ contain all constraints $\cnum{m}$ and $\Xi_{no}$ contain all constraints $\cnotnum{m}$. If $\Xi_{yes}$ contains $\cnum{m}$ and $\Xi_{no}$ contains $\cnotnum{m}$ for the same $m$, return \li{true}. If $\Xi_{yes}$ contains $\cnum{m_1}$ and $\cnum{m_2}$ with $m_1 \neq m_2$, return \li{true}. Otherwise, return \li{false}.
\end{enumerate}

Note that line (6) moves all constraints built up using $\land$ and $\lor$ to the front of the list, causing them to be expanded on lines (4) and (5) in the recursive call. Resultingly, after line (6), we can assume all constraints are "flattened" to an outermost non-$\land$ non-$\lor$ constructor. 
Correspondingly, the following lines each handle a different possibility for these outermost constructors, making use of the fact that all constraints in $\Xi$ are of the same type. On line (7), all constraints must be of the form $\cinl{\xi}$ or $\cinr{\xi}$, and we proceed according to \CINCInj, \CINCInl, and \CINCInr. Similarly, on line (8), we handle the case where all constraints are of the form $\cand{\xi_1}{\xi_2}$, checking inconsistency on each projection as in \CINCPairL and \CINCPairR. Finally, on line (9) we reach our base case, only having to handle constraints on our base number type, which is easily decidable. If Peanut is extended to include other base types, similar cases would have to be added following line (9).

With such a decision procedure, using the results of \autoref{theorem:exhaustive-truify},  \autoref{theorem:redundant-validity}, and \autoref{theorem:validity-inconsistency}, we now have decision procedures for exhaustiveness and redundancy. Note that the latter here theorem uses the fact that a constraint is equivalent to the dual of its dual.
\begin{theorem}
$\csatisfyormay{\ctruth}{\xi}$ if and only if $incon(\cdual{\ctruify{\xi}}) = true$.
\end{theorem}
\begin{theorem}
$\csatisfy{\xi_r}{\xi_{rs}}$ if and only if $incon(\cand{\ctruify{\xi_r}}{\cdual{\cfalsify{\xi_{rs}}}})  = true$.
\end{theorem}

\subsubsection{Witness Generation}
We have now shown how to decide both exhaustiveness and redundancy in the presence of holes. As discussed in \autoref{sec:background} and displayed in \autoref{fig:exhaustiveness} and \autoref{fig:redundancy}, such checks enable us to provide helpful feedback, statically eliminating large classes of bugs. However, note that simply reporting inexhaustivity with no further guidance may be quite frustrating for the user - we only opaquely state that at least one expression is unhandled, without ever giving a concrete example of such an expression. Particularly in the presence of holes, it may not be immediately clear why the inexhaustiveness arises.

To remedy such opaqueness, if our necessarily inexhaustive rules emit a constraint $\xi$, we must construct a value $e$ such that $\cnotsatisfyormay{e}{\xi}$. Equivalently, considering \autoref{theorem:exhaustive-truify}, we must construct a value $e$ such that $\cnotsatisfy{e}{\ctruify{\xi}}$, which, by \autoref{theorem:exclusive-complete-constraint-satisfaction}, is in turn equivalent to having $\csatisfy{e}{\cdual{\ctruify{\xi}}}$. That is, constructing a witness to inexhaustiveness can be reduced to the problem of constructing a witness for a fully known constraint.

Fortunately, constructing a witness only requires a slight modification of the $incon(\Xi)$ procedure we defined earlier. Indeed, the $\cincon{\Xi}$ judgement exactly pins down when it is impossible to construct a witness to a set of constraints $\Xi$, so it unsurprising that these algorithms are related. Formally, we give a procedure $witness(\Xi)$ where $\Xi$ is a set of constraints, either returning $None$ if $\Xi$ is inconsistent, or otherwise returning $Some(e)$ for a value $e$ with $\csatisfy{e}{\xi}$ for all $\xi \in \Xi$. 

\begin{enumerate}
\item If $\Xi$ is empty, return \li{Some}($e$) for any arbitrary expression $e$. Otherwise, let $\Xi = \xi, \Xi^\prime$.
\item If $\xi = \cfalsity$, return \li{None}.
\item If $\xi = \ctruth$, return $witness(\Xi^\prime)$.
\item If $\xi = \cand{\xi_1}{\xi_2}$, return $witness(\xi_1, \xi_2, \Xi^\prime)$.
\item If $\xi = \cor{\xi_1}{\xi_2}$, then compute $w_1 = witness(\xi_1, \Xi^\prime)$ and $w_2 = witness(\xi_2, \Xi^\prime)$. If both $w_1$ and $w_2$ are \li{None}, then return \li{None}. Otherwise, arbitrarily return whichever of $w_1$ and $w_2$ is not \li{None}.
\item Partition $\Xi$, letting $\Xi_{log}$ contain all constraints of the form $\cor{\xi_1}{\xi_2}$ or $\cand{\xi_1}{\xi_2}$ and letting $\Xi_{other}$ contains all other constraints. If $\Xi_{log}$ is non-empty, return $witness(\Xi_{log} \texttt{++}~ \Xi_{other})$.
\item If $\xi = \cinl{\xi^\prime}$ or $\xi = \cinr{\xi^\prime}$, return \li{None} if $\Xi^\prime$ contains any mismatching injection constructor. Otherwise, strip the outermost injection constructor from each element of $\Xi^\prime$ to produce a list $\Xi^\prime_{str}$. Compute $w = witness(\xi^\prime, \Xi^\prime_{str})$. If $w$ is \li{None} then return \li{None}. Otherwise, if $w$ is \li{Some}($e$), return \li{Some}($\cinl{e}$) if $\xi = \cinl{\xi^\prime}$ or \li{Some}($\cinr{e}$) if $\xi = \cinr{\xi^\prime}$.

\item If $\xi = \cpair{\xi_1, \xi_2}$, let $\Xi^\prime_1$ be the result of mapping $\cpair{\xi_1}{\xi_2} \mapsto \xi_1$ onto $\Xi^\prime$, and similarly, let $\Xi^\prime_2$ be the result of mapping $\cpair{\xi_1}{\xi_2} \mapsto \xi_2$ onto $\Xi^\prime$. Compute $w_1 = incon(\xi_1, \Xi^\prime_1)$ and $w_2 =  incon(\xi_2, \Xi^\prime_2)$. If $w_1$ is \li{Some}($e_1$) and $w_2$ is \li{Some}($e_2$), then return \li{Some}($\hpair{e_1}{e_2})$. Otherwise, return \li{None}.

\item If $\xi = \cnum{n}$ or $\xi = \cnotnum{n}$, then partition $\Xi$ into two lists, letting $\Xi_{yes}$ contain all constraints $\cnum{m}$ and $\Xi_{no}$ contain all constraints $\cnotnum{m}$. If $\Xi_{yes}$ contains $\cnum{m}$ and $\Xi_{no}$ contains $\cnotnum{m}$ for the same $m$, return \li{None}. If $\Xi_{yes}$ contains $\cnum{m_1}$ and $\cnum{m_2}$ with $m_1 \neq m_2$, return \li{None}. Otherwise, if $\Xi_{yes}$ is non-empty return \li{Some}($m$) for any $\cnum{m} \in \Xi_{yes}$, else return \li{Some}($m$) for any $m$ with $\cnotnum{m} \notin \Xi_{no}$.
\end{enumerate}

The above almost exactly follows the decision procedure $incon(\Xi)$, except that we actually construct a witness for the case of the base type on line (9), and at each recursive call, we wrap the result with an appropriate constructor to propagate such base witnesses upward, reporting inconsistency whenever this fails. In fact, then, our $witness(\Xi)$ procedure supersedes the need for the $incon(\Xi)$ procedure, with $witness(\Xi) = $~\li{None} exactly when $incon(\Xi) = true$.

On a final note, we can use a similar decision procedure to generate witnesses to irredundancy. That is, if $\cnotsatisfy{\xi_r}{\xi_{rs}}$, then in light of \autoref{theorem:redundant-validity}, $witness(\cand{\ctruify{\xi_r}}{\cdual{\cfalsify{\xi_{rs}}}})$ will be some value $e$ such that $\csatisfyormay{e}{\xi_r}$ and $\cnotsatisfy{e}{\xi_{rs}}$. As irredundancy is not an error, this is unlikely to be useful to the user, but it is interesting to note nonetheless.